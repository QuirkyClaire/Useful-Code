{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "471af668",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16acf356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    " \n",
    " \n",
    "def load_train(path):\n",
    "    features_train = np.load(path + 'train_features.npy')\n",
    "    target_train = np.load(path + 'train_target.npy')\n",
    "    features_train = features_train.reshape(features_train.shape[0], 28 * 28) / 255.\n",
    "    return features_train, target_train\n",
    " \n",
    " \n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=input_shape, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    " \n",
    "    return model\n",
    " \n",
    " \n",
    " \n",
    "def train_model(model, train_data, test_data, batch_size=32, epochs=10,\n",
    "               steps_per_epoch=None, validation_steps=None):\n",
    " \n",
    "    features_train, target_train = train_data\n",
    "    features_test, target_test = test_data\n",
    "    model.fit(features_train, target_train, \n",
    "              validation_data=(features_test, target_test),\n",
    "              batch_size=batch_size, epochs=epochs,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_steps=validation_steps,\n",
    "              verbose=2, shuffle=True)\n",
    " \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebc86a3",
   "metadata": {},
   "source": [
    "Версия АДАМ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eafc887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, AvgPool2D, MaxPooling2D\n",
    "\n",
    "def load_train(path):\n",
    "    features_train = np.load(path + 'train_features.npy')\n",
    "    target_train = np.load(path + 'train_target.npy')\n",
    "    features_train = features_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "    return features_train, target_train\n",
    "\n",
    "\n",
    "def create_model(input_shape):\n",
    "    optimizer = Adam(lr=0.01)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=6, kernel_size=(5, 5), padding='same',\n",
    "                     activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(AvgPool2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=8, kernel_size=(5, 5), padding='same',\n",
    "                     activation=\"relu\"))\n",
    "    model.add(AvgPool2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units=30, activation=\"relu\"))\n",
    "    model.add(Dense(units=20, activation=\"relu\"))\n",
    "    model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, train_data, test_data, batch_size=32, epochs=15,\n",
    "                steps_per_epoch=None, validation_steps=None):\n",
    "    features_train, target_train = train_data\n",
    "    features_test, target_test = test_data\n",
    "    model.fit(features_train, target_train,\n",
    "              validation_data=(features_test, target_test),\n",
    "              batch_size=batch_size, epochs=epochs,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_steps=validation_steps,\n",
    "              verbose=2, shuffle=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5540d9",
   "metadata": {},
   "source": [
    "Сверточная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, AvgPool2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_train(path):\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                 horizontal_flip=True,\n",
    "                                 vertical_flip=True)\n",
    "    train_datagen_flow = datagen.flow_from_directory(path,\n",
    "                                                     target_size=(150, 150),\n",
    "                                                     batch_size=16,\n",
    "                                                     class_mode='sparse',\n",
    "                                                     seed=12345)\n",
    "    return train_datagen_flow\n",
    "\n",
    "\n",
    "def create_model(input_shape):\n",
    "    optimizer = Adam(learning_rate = 0.0001)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=6, kernel_size=(5, 5), padding='same',\n",
    "                     activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(AvgPool2D(pool_size=(2, 2), strides=None, padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units=12, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, train_data, test_data, batch_size=None, epochs=10, steps_per_epoch=None, validation_steps=None):\n",
    "    model.fit(train_data,\n",
    "              validation_data=test_data,\n",
    "              batch_size=batch_size, epochs=epochs,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_steps=validation_steps,\n",
    "              verbose=2, shuffle=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8843f1",
   "metadata": {},
   "source": [
    "Реснет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6ddf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, AveragePooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def load_train(path):\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "    train_datagen_flow = datagen.flow_from_directory(\n",
    "        path,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=16,\n",
    "        class_mode='sparse',\n",
    "        seed=12345\n",
    "    )\n",
    "\n",
    "    return train_datagen_flow\n",
    "\n",
    "\n",
    "def create_model(input_shape):\n",
    "    backbone = ResNet50(input_shape=input_shape,\n",
    "                        weights='imagenet',\n",
    "                        include_top=False)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(backbone)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=Adam(lr=0.001), metrics=['acc'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, train_data, test_data, batch_size=None, epochs=5,\n",
    "                steps_per_epoch=None, validation_steps=None):\n",
    "    model.fit(train_data,\n",
    "              validation_data=test_data,\n",
    "              batch_size=batch_size, epochs=epochs,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_steps=validation_steps,\n",
    "              verbose=2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a309cb65",
   "metadata": {},
   "source": [
    "Код для проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91efa144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, GlobalAveragePooling2D\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_train(path):\n",
    "    datagen = ImageDataGenerator(validation_split=0.25, rescale=1./255)\n",
    "    labels = pd.read_csv(path + 'labels.csv')\n",
    "    train_datagen_flow = datagen.flow_from_dataframe(dataframe=labels,\n",
    "                                                     directory=path + 'final_files/',\n",
    "                                                     x_col='file_name',\n",
    "                                                     y_col='real_age',\n",
    "                                                     target_size=(224, 224),\n",
    "                                                     batch_size=16,\n",
    "                                                     class_mode='raw',\n",
    "                                                     subset='training',\n",
    "                                                     seed=12345)\n",
    "    return train_datagen_flow\n",
    "\n",
    "def load_test(path):\n",
    "    datagen = ImageDataGenerator(validation_split=0.25, rescale=1./255)\n",
    "    labels = pd.read_csv(path + 'labels.csv')\n",
    "    test_datagen_flow = datagen.flow_from_dataframe(dataframe=labels,\n",
    "                                                     directory=path + 'final_files/',\n",
    "                                                     x_col='file_name',\n",
    "                                                     y_col='real_age',\n",
    "                                                     target_size=(224, 224),\n",
    "                                                     batch_size=16,\n",
    "                                                     class_mode='raw',\n",
    "                                                     subset='validation',\n",
    "                                                     seed=12345)\n",
    "    return test_datagen_flow\n",
    "\n",
    "\n",
    "def create_model(input_shape):\n",
    "    backbone = ResNet50(input_shape=input_shape, weights='imagenet', include_top=False)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(backbone)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(units=1, activation='relu'))\n",
    "\n",
    "    optimizer = Adam(lr=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, train_data, test_data, batch_size=None, epochs=5,\n",
    "               steps_per_epoch=None, validation_steps=None):\n",
    "\n",
    "    if steps_per_epoch is None:\n",
    "        steps_per_epoch = len(train_data)\n",
    "    if validation_steps is None:\n",
    "        validation_steps=len(test_data)\n",
    "\n",
    "    model.fit(train_data,\n",
    "              validation_data=test_data,\n",
    "              batch_size=batch_size, epochs=epochs,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_steps=validation_steps,\n",
    "              verbose=2, shuffle=True)\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
